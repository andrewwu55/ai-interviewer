{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader \n",
    "import pypandoc \n",
    "from pathlib import Path \n",
    "import text_lloom.workbench as wb\n",
    "import pandas as pd \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = Path('./data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r1_texts = [] \n",
    "for fpath in data_fpath.glob('*/R1.*'): \n",
    "    if str(fpath).endswith('pdf'): \n",
    "        reader = PdfReader(fpath)\n",
    "        full_text = \"\" \n",
    "        for page in reader.pages: \n",
    "            full_text += page.extract_text() \n",
    "    elif str(fpath).endswith('docx'): \n",
    "        full_text = pypandoc.convert_file(\n",
    "            fpath, \n",
    "            'markdown',\n",
    "            format='docx'\n",
    "        )\n",
    "    all_r1_texts.append({\n",
    "        'doc_id': f\"{str(fpath.parent).split('/')[1]}_R1\", \n",
    "        'content': full_text \n",
    "    })\n",
    "\n",
    "\n",
    "all_r2_texts = [] \n",
    "for fpath in data_fpath.glob('*/R2.*'): \n",
    "    if str(fpath).endswith('pdf'): \n",
    "        reader = PdfReader(fpath)\n",
    "        full_text = \"\" \n",
    "        for page in reader.pages: \n",
    "            full_text += page.extract_text() \n",
    "    elif str(fpath).endswith('docx'): \n",
    "        full_text = pypandoc.convert_file(\n",
    "            fpath, \n",
    "            'markdown',\n",
    "            format='docx'\n",
    "        )\n",
    "    all_r2_texts.append({\n",
    "        'doc_id': f\"{str(fpath.parent).split('/')[1]}_R2\", \n",
    "        'content': full_text \n",
    "    })\n",
    "\n",
    "\n",
    "all_r3_texts = [] \n",
    "for fpath in data_fpath.glob('*/R3.*'): \n",
    "    if str(fpath).endswith('pdf'): \n",
    "        reader = PdfReader(fpath)\n",
    "        full_text = \"\" \n",
    "        for page in reader.pages: \n",
    "            full_text += page.extract_text() \n",
    "    elif str(fpath).endswith('docx'): \n",
    "        full_text = pypandoc.convert_file(\n",
    "            fpath, \n",
    "            'markdown',\n",
    "            format='docx'\n",
    "        )\n",
    "    all_r3_texts.append({\n",
    "        'doc_id': f\"{str(fpath.parent).split('/')[1]}_R3\", \n",
    "        'content': full_text \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_df = pd.DataFrame(all_r1_texts)\n",
    "r2_df = pd.DataFrame(all_r2_texts)\n",
    "r3_df = pd.DataFrame(all_r3_texts)\n",
    "all_df = pd.DataFrame(all_r1_texts + all_r2_texts + all_r3_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R1 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = wb.lloom(\n",
    "    df=r1_df,\n",
    "    text_col=\"content\", \n",
    "    id_col='doc_id' \n",
    ")\n",
    "r1_score_df = await l.gen_auto(\n",
    "    max_concepts=10, \n",
    "    seed=\"Discussion points in a referee report for an academic finance article based on the paper's content\", \n",
    "    n_synth=1, \n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_score_df.merge(r1_df, on='doc_id', how='left').to_parquet('./data/r1_dataset.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = wb.lloom(\n",
    "    df=r2_df,\n",
    "    text_col=\"content\", \n",
    "    id_col='doc_id' \n",
    ")\n",
    "r2_score_df = await l.gen_auto(\n",
    "    max_concepts=10, \n",
    "    seed=\"Discussion points in a referee report for an academic finance article based on the paper's content\", \n",
    "    n_synth=1, \n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_df.merge(r2_df, on='doc_id', how='left').to_parquet('./data/r2_dataset.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R3 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = wb.lloom(\n",
    "    df=r3_df,\n",
    "    text_col=\"content\", \n",
    "    id_col='doc_id' \n",
    ")\n",
    "r3_score_df = await l.gen_auto(\n",
    "    max_concepts=10, \n",
    "    seed=\"Specific discussion points in a referee report for an academic finance article based solely on the paper's content. Do not include the editorial recommendation\", \n",
    "    n_synth=1, \n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3_score_df.loc[r3_score_df['concept_prompt'] == \"Does the text address the intergenerational consequences of technological shocks on workers' children?\", 'concept_name'] = 'Effect of Technological Shocks on Children'\n",
    "r3_score_df.loc[r3_score_df['concept_prompt'] == \"Does the text example examine the intergenerational effects of economic changes or disruptions?\", 'concept_name'] = 'Intergenerational Effects of Economic Changes or Disruptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3_score_df.merge(r3_df, on='doc_id', how='left').to_parquet('./data/r3_dataset.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R1 + R2 + R3 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = wb.lloom(\n",
    "    df=all_df,\n",
    "    text_col=\"content\", \n",
    "    id_col='doc_id' \n",
    ")\n",
    "all_score_df = await l.gen_auto(\n",
    "    max_concepts=8, \n",
    "    seed=\"General and high-level discussion points in a referee report for an academic finance article such as theory, methodology, data, results, policy implications, limitations, and directions for future research.\", \n",
    "    n_synth=1, \n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score_df.merge(all_df, on='doc_id', how='left').to_parquet('./data/all_dataset.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordtangible import avg_text_concreteness \n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from huggingface_hub import login\n",
    "\n",
    "# This will prompt for your token or you can pass it directly\n",
    "login(token='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_tokenizer = AutoTokenizer.from_pretrained(\"gtfintechlab/SubjECTiveQA-SPECIFIC\", do_lower_case=True, do_basic_tokenize=True)\n",
    "specificity_model = AutoModelForSequenceClassification.from_pretrained(\"gtfintechlab/SubjECTiveQA-SPECIFIC\", num_labels=3)\n",
    "specificity_config = AutoConfig.from_pretrained(\"gtfintechlab/SubjECTiveQA-SPECIFIC\")\n",
    "specificity_classifier = pipeline('text-classification', model=specificity_model, tokenizer=specificity_tokenizer, config=specificity_config, framework=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['round'] = all_df['doc_id'].str.split('_').str[1].str[1:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['concreteness'] = all_df['content'].apply(avg_text_concreteness)\n",
    "all_df['subjectiveness'] = all_df['content'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "all_df['specificity'] = all_df['content'].apply(lambda x: specificity_classifier(x, batch_size=128, truncation='only_first', max_length=512)[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_parquet('./data/nlp_scores.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-interviewer-4bNf2K9S",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
