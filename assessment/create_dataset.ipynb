{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import openai \n",
    "from transformers import pipeline \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sentence_transformers import SentenceTransformer \n",
    "import hashlib \n",
    "import text_lloom.workbench as wb\n",
    "import os\n",
    "import yake \n",
    "import pypandoc \n",
    "from pathlib import Path \n",
    "\n",
    "from utils import turn_level_annotation, referee_report_annotation\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "dataframes = [] \n",
    "for f in files: \n",
    "    tmp = pd.read_csv(f) \n",
    "    tmp = tmp.reset_index(names='conversation_order')\n",
    "    tmp['content_id'] = (tmp['time'] + tmp['session_id'] + tmp['role'] + tmp['content']).apply(lambda x: hashlib.sha256(x.encode()).hexdigest()) \n",
    "    dataframes.append(tmp)\n",
    "\n",
    "df = pd.concat(dataframes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key \n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o-mini-2024-07-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "sentiment_analyzer = pipeline('sentiment-analysis', model=model_path, tokenizer=model_path, truncation=True, max_length=512)\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['content'].apply(lambda x: len(re.findall(r'\\S+', x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Between Responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['time'])\n",
    "df['time_spent'] = df.groupby('session_id')['datetime'].diff().dt.total_seconds() / 60 \n",
    "df = df.drop(columns=['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = [] \n",
    "past_messages = [] \n",
    "for row in df.to_dict('records'): \n",
    "    if row['role'] == 'user': \n",
    "        annotation = turn_level_annotation(client, model, past_messages, row['content'])\n",
    "        past_messages.append(row) \n",
    "        row.update(annotation) \n",
    "        annotated_data.append(row) \n",
    "    else: \n",
    "        past_messages.append(row) \n",
    "        annotated_data.append(row) \n",
    "\n",
    "df = pd.DataFrame(annotated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['content'].apply(lambda x: sentiment_analyzer(x)[0]['label']).map({'positive': 1, 'neutral': 0, 'negative': -1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Coverage \n",
    "\n",
    "Use LLooM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = wb.lloom(\n",
    "    df=df.loc[df['role'] == 'user'],\n",
    "    text_col=\"content\", \n",
    "    id_col='content_id' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = await l.gen_auto(\n",
    "    max_concepts=5, \n",
    "    seed=\"Discussion points for a peer review of an academic finance article\", \n",
    "    n_synth=1, \n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    extractor = yake.KeywordExtractor(top=10)\n",
    "    keywords_scores = extractor.extract_keywords(text)\n",
    "    keywords = [kw for kw, score in keywords_scores]\n",
    "    return keywords\n",
    "\n",
    "df['keywords'] = df['content'].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consecutive Semantic Similarity \n",
    "\n",
    "Measure the semantic similarity between interviewer message and user response in consecutive terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = [] \n",
    "last_interviewer_msg = None \n",
    "for row in df.to_dict('records'): \n",
    "    if row['role'] == 'user': \n",
    "        interviewer = embedding_model.encode(last_interviewer_msg)\n",
    "        user = embedding_model.encode(row['content'])\n",
    "        row['semantic_similarity'] = cosine_similarity(interviewer.reshape(1, -1), user.reshape(1, -1))[0][0]\n",
    "    else: \n",
    "        last_interviewer_msg = row['content']\n",
    "    annotated_data.append(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(annotated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Report Annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "for fpath in report_files: \n",
    "    fpath = Path(fpath) \n",
    "    fname = fpath.name\n",
    "    username = fname.split('+')[1]\n",
    "    report = pypandoc.convert_file(\n",
    "        fpath, \n",
    "        'markdown', \n",
    "        format='docx'\n",
    "    )\n",
    "    annotation = referee_report_annotation(client, model, report)\n",
    "    annotation['user'] = username \n",
    "    data.append(annotation)\n",
    "report_df = pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./turn_level_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = score_df.rename(columns={'doc_id': 'content_id'}).merge(df, on='content_id', how='left').sort_values(['user', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.to_csv('./topic_level_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.to_csv('./report_level_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-interviewer-4bNf2K9S",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
