{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud \n",
    "import textwrap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_level_df = pd.read_csv('./turn_level_data.csv') \n",
    "topic_level_df = pd.read_csv('./topic_level_data.csv') \n",
    "report_level_df = pd.read_csv('./report_level_data.csv')\n",
    "\n",
    "concept_map = topic_level_df[['concept_name', 'concept_prompt']].drop_duplicates().set_index('concept_name')['concept_prompt'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_score = (topic_level_df.groupby(['user', 'concept_name'])['score'].sum() / topic_level_df.groupby('user')['score'].sum()).reset_index().groupby('concept_name')['score'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'cchen'\n",
    "user_turn_level_df = turn_level_df.loc[turn_level_df['user'] == user].copy() \n",
    "user_topic_level_df = topic_level_df.loc[topic_level_df['user'] == user].copy() \n",
    "user_topic_score = user_topic_level_df.groupby('concept_name')['score'].sum() / user_topic_level_df['score'].sum()\n",
    "user_report_df = report_level_df.loc[report_level_df['user'] == user]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'Metric': 'Total Turns', 'Value': len(user_turn_level_df)}, \n",
    "    {'Metric': 'Number of AI Turns', 'Value': (user_turn_level_df['role'] == 'assistant').sum()},\n",
    "    {'Metric': 'Number of User Turns', 'Value': (user_turn_level_df['role'] == 'user').sum()},\n",
    "] \n",
    "data.append({\n",
    "    'Metric': 'Avg Number of Words in User Response', \n",
    "    'Value': f\"{user_turn_level_df.loc[user_turn_level_df['role'] == 'user']['word_count'].mean():,.2f}\"\n",
    "})\n",
    "data.append({\n",
    "    'Metric': 'Avg Number of Minutes Spent for User Response', \n",
    "    'Value': f\"{user_turn_level_df.loc[user_turn_level_df['role'] == 'user']['time_spent'].mean():,.2f}\"\n",
    "})\n",
    "for col in ['relevance', 'specificity', 'clarity', 'constructiveness', 'politeness', 'sentiment', 'overall']: \n",
    "    data.append({\n",
    "        'Metric': f\"Avg {col.capitalize()} Score\", \n",
    "        'Value': f\"{user_turn_level_df.loc[user_turn_level_df['role'] == 'user'][col].mean():,.2f}\"\n",
    "    })\n",
    "data.append({\n",
    "    'Metric': 'Most Discussed Topic', \n",
    "    'Value': f\"{user_topic_score.idxmax()} ({user_topic_score.max():,.2%})\"\n",
    "})\n",
    "data.append({\n",
    "    'Metric': 'Topic Variation', \n",
    "    'Value': f\"{user_topic_score.std():,.2%}\"\n",
    "})\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8), facecolor='w') \n",
    "data = user_topic_score.sort_values().copy() \n",
    "# data.index = [textwrap.fill(concept_map[item].strip(), width=40) for item in data.index]\n",
    "data.plot.barh(ax=ax)\n",
    "ax.set_xlabel('Percent of Topic Coverage')\n",
    "ax.set_ylabel('Topic')\n",
    "ax.xaxis.set_major_formatter(\"{x:,.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_topic_level_df.loc[user_topic_level_df['score'] == 1].groupby('concept_name').agg(\n",
    "    num_turns=pd.NamedAgg(column='content_id', aggfunc='count'), \n",
    "    avg_word_count=pd.NamedAgg(column='word_count', aggfunc='mean'),\n",
    "    avg_time_spent=pd.NamedAgg(column='time_spent', aggfunc='mean'),\n",
    "    avg_relevance=pd.NamedAgg(column='relevance', aggfunc='mean'),\n",
    "    avg_specificity=pd.NamedAgg(column='specificity', aggfunc='mean'),\n",
    "    avg_clarity=pd.NamedAgg(column='clarity', aggfunc='mean'),\n",
    "    avg_constructiveness=pd.NamedAgg(column='constructiveness', aggfunc='mean'),\n",
    "    avg_politeness=pd.NamedAgg(column='politeness', aggfunc='mean'),\n",
    "    avg_sentiment=pd.NamedAgg(column='sentiment', aggfunc='mean'),\n",
    "    avg_overall=pd.NamedAgg(column='overall', aggfunc='mean'),\n",
    "    avg_semantic_similarity=pd.NamedAgg(column='semantic_similarity', aggfunc='mean'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color='white', \n",
    "    colormap='coolwarm'\n",
    ").generate(' '.join([' '.join(eval(kw_list)) for kw_list in user_turn_level_df.loc[user_turn_level_df['role'] == 'user']['keywords']]))\n",
    "fig, ax = plt.subplots(figsize=(10, 8), facecolor='w') \n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Peers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'Metric': 'Total Turns', 'User Value': len(user_turn_level_df), 'Avg Student Value': turn_level_df.groupby('user')['time'].count().mean()}, \n",
    "    {'Metric': 'Number of AI Turns', 'User Value': (user_turn_level_df['role'] == 'assistant').sum(), 'Avg Student Value': turn_level_df.loc[turn_level_df['role'] == 'assistant'].groupby('user')['time'].count().mean()}, \n",
    "    {'Metric': 'Number of User Turns', 'User Value': (user_turn_level_df['role'] == 'user').sum(), 'Avg Student Value': turn_level_df.loc[turn_level_df['role'] == 'user'].groupby('user')['time'].count().mean()}, \n",
    "] \n",
    "data.append({\n",
    "    'Metric': 'Avg Number of Words in User Response', \n",
    "    'User Value': f\"{user_turn_level_df.loc[user_turn_level_df['role'] == 'user']['word_count'].mean():,.2f}\", \n",
    "    'Avg Student Value': f\"{turn_level_df.loc[turn_level_df['role'] == 'user'].groupby('user')['word_count'].mean().mean():,.2f}\"\n",
    "})\n",
    "data.append({\n",
    "    'Metric': 'Avg Number of Words in AI Response', \n",
    "    'User Value': f\"{user_turn_level_df.loc[user_turn_level_df['role'] == 'assistant']['word_count'].mean():,.2f}\", \n",
    "    'Avg Student Value': f\"{turn_level_df.loc[turn_level_df['role'] == 'assistant'].groupby('user')['word_count'].mean().mean():,.2f}\"\n",
    "})\n",
    "data.append({\n",
    "    'Metric': 'Avg Number of Minutes Spent for User Response', \n",
    "    'User Value': f\"{user_turn_level_df.loc[user_turn_level_df['role'] == 'user']['time_spent'].mean():,.2f}\", \n",
    "    'Avg Student Value': f\"{turn_level_df.loc[turn_level_df['role'] == 'user'].groupby('user')['time_spent'].mean().mean():,.2f}\"\n",
    "})\n",
    "for col in ['relevance', 'specificity', 'clarity', 'constructiveness', 'politeness', 'sentiment', 'overall']: \n",
    "    data.append({\n",
    "        'Metric': f\"Avg {col.capitalize()} Score\", \n",
    "        'User Value': f\"{user_turn_level_df.loc[user_turn_level_df['role'] == 'user'][col].mean():,.2f}\", \n",
    "        'Avg Student Value': f\"{turn_level_df.loc[turn_level_df['role'] == 'user'].groupby('user')[col].mean().mean():,.2f}\"\n",
    "    })\n",
    "data.append({\n",
    "    'Metric': 'Most Discussed Topic', \n",
    "    'User Value': f\"{user_topic_score.idxmax()} ({user_topic_score.max():,.2%})\", \n",
    "    'Avg Student Value': f\"{topic_score.idxmax()} ({topic_score.max():,.2%})\"\n",
    "})\n",
    "data.append({\n",
    "    'Metric': 'Topic Variation', \n",
    "    'User Value': f\"{user_topic_score.std():,.2%}\", \n",
    "    'Avg Student Value': f\"{topic_score.std():,.2%}\"\n",
    "})\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color='white', \n",
    "    colormap='coolwarm'\n",
    ").generate(' '.join([' '.join(eval(kw_list)) for kw_list in turn_level_df.loc[turn_level_df['role'] == 'user']['keywords']]))\n",
    "fig, ax = plt.subplots(figsize=(10, 8), facecolor='w') \n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'User': user_topic_score.sort_values().copy(),\n",
    "    'Avg Student': topic_score.reindex(user_topic_score.sort_values().index).copy()\n",
    "})\n",
    "# df.index = [textwrap.fill(concept_map[item].strip(), width=40) for item in df.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8), facecolor='w')\n",
    "df.plot.barh(ax=ax)\n",
    "\n",
    "ax.set_xlabel('Percent of Topic Coverage')\n",
    "ax.set_ylabel('Topic')\n",
    "ax.legend(title='Data Series')\n",
    "ax.xaxis.set_major_formatter('{x:,.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), facecolor='w')\n",
    "data = user_topic_score - topic_score \n",
    "# data.index = [textwrap.fill(concept_map[item].strip(), width=40) for item in data.index]\n",
    "data.plot.barh(ax=ax)\n",
    "ax.set_xlabel('User Percent of Topic Coverage Difference from Average')\n",
    "ax.set_ylabel('Topic')\n",
    "ax.xaxis.set_major_formatter(\"{x:,.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with Final Report Quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_turn_scores = turn_level_df.loc[turn_level_df['role'] == 'user'].groupby('user')[['word_count', 'time_spent', 'relevance', 'specificity', 'clarity', 'constructiveness', 'politeness', 'sentiment', 'overall', 'semantic_similarity']].mean()\n",
    "user_turn_scores.columns = [f\"user_{col}\" for col in user_turn_scores.columns]\n",
    "report_level_df = report_level_df.merge(user_turn_scores.reset_index(), on='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_level_df[['user_word_count', 'user_time_spent', 'user_relevance', 'user_specificity', 'user_clarity', 'user_constructiveness', 'user_politeness', 'user_sentiment', 'user_overall', 'user_semantic_similarity', 'overall']].corr()['overall']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-interviewer-4bNf2K9S",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
